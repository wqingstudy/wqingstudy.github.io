<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Redis主从复制</title>
      <link href="/posts/b7e51ad7.html"/>
      <url>/posts/b7e51ad7.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a>Redis主从复制</h1><h2 id="1-主从复制简介"><a href="#1-主从复制简介" class="headerlink" title="1. 主从复制简介"></a>1. 主从复制简介</h2><p><strong>互联网“三高”架构</strong></p><ul><li>高并发</li><li>高性能</li><li>高可用</li></ul><h3 id="1-1-单机-Redis-是否高可用"><a href="#1-1-单机-Redis-是否高可用" class="headerlink" title="1.1 单机 Redis 是否高可用"></a>1.1 单机 Redis 是否高可用</h3><p>单机redis的风险与问题</p><p>问题1.机器故障</p><ul><li>现象： 硬盘故障、系统崩溃</li><li>本质： 数据丢失，很可能对业务造成灾难性打击</li><li>结论： 基本上会放弃使用redis.</li></ul><p>问题2.容量瓶颈  </p><ul><li><p>现象：内存不足，从16G升级到64G，从64G升级到128G，无限升级内存</p></li><li><p>本质：穷，硬件条件跟不上</p></li><li><p>结论：放弃使用redis</p></li></ul><p>结论：</p><p>为了避免单点Redis服务器故障，准备多台服务器，互相连通。 将数据复制多个副本保存在不同的服务器上， <strong>连接在一起</strong>， 并保证数据是<strong>同步</strong>的。 即使有其中一台服务器宕机，其他服务器依然可以继续提供服务，实现Redis的高可用， 同时实现数据<strong>冗余备份</strong>。  </p><h3 id="1-2-主从复制"><a href="#1-2-主从复制" class="headerlink" title="1.2 主从复制"></a>1.2 主从复制</h3><p>单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。</p><p>主从复制即将master中的数据即时、有效的复制到slave中</p><p>特征：一个master可以拥有多个slave，一个slave只对应一个master</p><p>职责：</p><ul><li>master<ul><li>写数据</li><li>执行写操作时，将出现变化的数据自动同步到slave</li><li>读数据（可忽略）</li></ul></li><li>slave<ul><li>读数据</li><li>写数据（禁止）</li></ul></li></ul><p>需要解决的问题：<strong>数据同步</strong><br>核心工作：<strong>master的数据复制到slave中</strong>  </p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903162452359.png" alt="image-20220903162452359"></p><h3 id="1-3-主从复制的作用"><a href="#1-3-主从复制的作用" class="headerlink" title="1.3 主从复制的作用"></a>1.3 主从复制的作用</h3><ul><li>读写分离： master写、 slave读，提高服务器的读写负载能力</li><li>负载均衡： 基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量</li><li>故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复</li><li>数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式</li><li>高可用基石： 基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案</li></ul><h2 id="2-主从复制的搭建"><a href="#2-主从复制的搭建" class="headerlink" title="2. 主从复制的搭建"></a>2. 主从复制的搭建</h2><blockquote><p>环境：</p><p>CentOS：7.9</p><p>Redis 6.2.6</p></blockquote><h3 id="2-1-配置文件的准备"><a href="#2-1-配置文件的准备" class="headerlink" title="2.1 配置文件的准备"></a>2.1 配置文件的准备</h3><p><strong>步骤一：Master配置文件</strong></p><p><code>redis-6381.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">bind</span> 127.0.0.1</span><br><span class="line">port 6381</span><br><span class="line"><span class="comment">#daemonize no</span></span><br><span class="line"><span class="comment">#logfile &quot;6381.log&quot;</span></span><br><span class="line"><span class="built_in">dir</span> /redis/data</span><br><span class="line">dbfilename <span class="string">&quot;dump-6381&quot;</span></span><br><span class="line">appendfilename <span class="string">&quot;appendonly-6381&quot;</span></span><br></pre></td></tr></table></figure><p>步骤二：Slave1、Slave2的配置文件</p><p>执行命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">&quot;s/6381/6382/g&quot;</span> redis-6381.conf &gt; redis-6382.conf</span><br><span class="line">sed <span class="string">&quot;s/6381/6383/g&quot;</span> redis-6381.conf &gt; redis-6383.conf</span><br></pre></td></tr></table></figure><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903163550548.png" alt="image-20220903163550548"></p><h3 id="2-2-开始搭建"><a href="#2-2-开始搭建" class="headerlink" title="2.2 开始搭建"></a>2.2 开始搭建</h3><p>步骤一：Master的搭建</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903164427961.png" alt="image-20220903164427961"></p><p>步骤二：启动 Slave1(6382)</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903164655552.png" alt="image-20220903164655552"></p><p>步骤三：测试一</p><ol><li>在6381，设置一个值，并在6382 尝试获取</li></ol><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903165126308.png" alt="image-20220903165126308"></p><ol start="2"><li>执行 <code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof 127.0.0.1 6381</span><br></pre></td></tr></table></figure><ol start="3"><li>再次获取<br><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903165419075.png" alt="image-20220903165419075"></li></ol><p>步骤四：启动Slave2(6383)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server -slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br></pre></td></tr></table></figure><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903170313321.png" alt="image-20220903170313321"></p><p>连接客户端</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903170405897.png" alt="image-20220903170405897"></p><p>步骤五：查看data目录</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903170532195.png" alt="image-20220903170532195"></p><blockquote><p>我们并未开启rdb持久化，但是还是生成了rdb文件。</p><p>结论:主从复制过程是通过rdb文件来实现的</p></blockquote><h3 id="2-3-主从连接"><a href="#2-3-主从连接" class="headerlink" title="2.3 主从连接"></a>2.3 主从连接</h3><p>主从连接的方式（ slave连接master）</p><ul><li><p>方式一：客户端发送命令  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line">REPLICAOF host port</span><br></pre></td></tr></table></figure></li><li><p>方式二：启动服务器参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server -slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br></pre></td></tr></table></figure></li><li><p>方式三：服务器配置，在配置文件中配置(主流)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br></pre></td></tr></table></figure><p>例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bind 127.0.0.1</span><br><span class="line">port 6382</span><br><span class="line">#daemonize no</span><br><span class="line">#logfile &quot;6382.log&quot;</span><br><span class="line">dir /redis/data</span><br><span class="line">dbfilename &quot;dump-6382&quot;</span><br><span class="line">appendfilename &quot;appendonly-6382&quot;</span><br><span class="line">slaveof 127.0.0.1 6381</span><br></pre></td></tr></table></figure></li></ul><p>master系统信息</p><p>执行 info 命令</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903171621726.png" alt="image-20220903171621726"></p><p>slave系统信息</p><p>执行 info 命令</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903171747953.png" alt="image-20220903171747953"></p><h3 id="2-4-主从断开连接"><a href="#2-4-主从断开连接" class="headerlink" title="2.4 主从断开连接"></a>2.4 主从断开连接</h3><p>客户端发送命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof no one</span><br></pre></td></tr></table></figure><blockquote><p>说明：<br>slave断开连接后，不会删除已有数据，只是不再接受master发送的数据  </p></blockquote><h3 id="2-5-授权访问"><a href="#2-5-授权访问" class="headerlink" title="2.5 授权访问"></a>2.5 授权访问</h3><p>Master设置密码</p><ul><li><p>master客户端发送命令设置密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config <span class="built_in">set</span> requirepass &lt;password&gt;</span><br><span class="line">config get requirepass</span><br></pre></td></tr></table></figure></li><li><p>master配置文件设置密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requirepass &lt;password&gt;</span><br></pre></td></tr></table></figure></li></ul><p>Slave设置密码</p><ul><li><p>slave客户端发送命令设置密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auth &lt;password&gt;</span><br></pre></td></tr></table></figure></li><li><p>slave配置文件设置密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">masterauth &lt;password&gt;</span><br></pre></td></tr></table></figure></li><li><p>slave启动服务器设置密码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server –a &lt;password&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="3-主从数据同步原理"><a href="#3-主从数据同步原理" class="headerlink" title="3. 主从数据同步原理"></a>3. 主从数据同步原理</h2><h3 id="3-1-全量同步"><a href="#3-1-全量同步" class="headerlink" title="3.1 全量同步"></a>3.1 全量同步</h3><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190004847.png" alt="image-20220903190004847"></p><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新d的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190031928.png" alt="image-20220903190031928"></p><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><h3 id="3-2-增量同步"><a href="#3-2-增量同步" class="headerlink" title="3.2 增量同步"></a>3.2 增量同步</h3><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190135225.png" alt="image-20220903190135225"></p><p>那么master怎么知道slave与自己的数据差异在哪里呢?</p><h3 id="3-3-repl-backlog原理"><a href="#3-3-repl-backlog原理" class="headerlink" title="3.3 repl_backlog原理"></a>3.3 repl_backlog原理</h3><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190256024.png" alt="image-20220903190256024"></p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190317020.png" alt="image-20220903190317020"></p><p>直到数组被填满:</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190331696.png" alt="image-20220903190331696"></p><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190349475.png" alt="image-20220903190349475"></p><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190403261.png" alt="image-20220903190403261"></p><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190422168.png" alt="image-20220903190422168"></p><h3 id="3-4-心跳机制"><a href="#3-4-心跳机制" class="headerlink" title="3.4 心跳机制"></a>3.4 心跳机制</h3><p>进入命令传播阶段候， master与slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线</p><p>master心跳：</p><ul><li>指令：PING</li><li>周期：由repl-ping-slave-period决定，默认10秒</li><li>作用：判断slave是否在线</li><li>查询：INFO replication  获取slave最后一次连接时间间隔， lag项维持在0或1视为正常</li></ul><p>slave心跳任务:</p><ul><li>指令：REPLCONF ACK {offset}</li><li>周期：1秒</li><li>作用1：汇报slave自己的复制偏移量，获取最新的数据变更指令</li><li>作用2：判断master是否在线</li></ul><p><strong>心跳阶段注意事项</strong></p><p>当slave多数掉线，或延迟过高时， master为保障数据稳定性，将拒绝所有信息同步操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 2</span><br><span class="line">min-slaves-max-lag 8</span><br></pre></td></tr></table></figure><p>slave数量少于2个，或者所有slave的延迟都大于等于10秒时，强制关闭master写功能，停止数据同步  </p><ul><li>slave数量由slave发送REPLCONF ACK命令做确认</li><li>slave延迟由slave发送REPLCONF ACK命令做确认</li></ul><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903194658003.png" alt="image-20220903194658003"></p><h3 id="3-4-主从同步优化"><a href="#3-4-主从同步优化" class="headerlink" title="3.4 主从同步优化"></a>3.4 主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903190827831.png" alt="image-20220903190827831"></p><h3 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5 小结"></a>3.5 小结</h3><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。</li><li>增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave节点第一次连接master节点时</li><li>slave节点断开时间太久，repl_baklog中的offset已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave节点断开又恢复，并且在repl_baklog中能找到offset时</li></ul>]]></content>
      
      
      <categories>
          
          <category> DataBase </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis数据删除与淘汰策略</title>
      <link href="/posts/7839a899.html"/>
      <url>/posts/7839a899.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis数据删除与淘汰策略"><a href="#Redis数据删除与淘汰策略" class="headerlink" title="Redis数据删除与淘汰策略"></a>Redis数据删除与淘汰策略</h1><h2 id="1-Redis中的数据特征"><a href="#1-Redis中的数据特征" class="headerlink" title="1. Redis中的数据特征"></a>1. Redis中的数据特征</h2><p>Redis是一种内存级数据库，所有数据均放在内存中，内存中的数据可以根据 <code>TTL</code> 指令获取其状态。</p><ul><li>xx：具有时效性的数据</li><li>-1：永久有效的数据</li><li>-2：已经过期的数据 或 被删除的数据 或 未定义的数据</li></ul><h3 id="1-1-时效性数据的存储结构"><a href="#1-1-时效性数据的存储结构" class="headerlink" title="1.1 时效性数据的存储结构"></a>1.1 时效性数据的存储结构</h3><p>Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903110214834.png" alt="image-20220903110214834"></p><p>过期字典是存储在 redisDb 这个结构里的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    dict *dict;     <span class="comment">//数据库键空间,保存着数据库中所有键值对</span></span><br><span class="line">    dict *expires   <span class="comment">// 过期字典,保存着键的过期时间</span></span><br><span class="line">    ...</span><br><span class="line">&#125; redisDb;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-数据删除策略"><a href="#2-数据删除策略" class="headerlink" title="2. 数据删除策略"></a>2. 数据删除策略</h2><ol><li>定时删除</li><li>惰性删除</li><li>定期删除</li></ol><p><strong>数据删除策略的目标</strong></p><p>在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或内存泄露。</p><h3 id="2-1-定时删除"><a href="#2-1-定时删除" class="headerlink" title="2.1 定时删除"></a>2.1 定时删除</h3><p>创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作  </p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903110130498.png" alt="image-20220903110130498"></p><p>优点：节约内存，到时就删除，快速释放掉不必要的内存占用</p><p>缺点： CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量</p><p>总结：用处理器性能换取存储空间（拿时间换空间）</p><h3 id="2-2-惰性删除"><a href="#2-2-惰性删除" class="headerlink" title="2.2 惰性删除"></a>2.2 惰性删除</h3><p>数据到达过期时间，不做处理。等下次访问该数据时</p><ul><li>如果未过期，返回数据</li><li>发现已过期，删除，返回不存在</li></ul><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903110832025.png" alt="image-20220903110832025"></p><p>优点：节约CPU性能，发现必须删除的时候才删除</p><p>缺点：内存压力很大，出现长期占用内存的数据</p><p>总结：用存储空间换取处理器性能（拿时间换空间）</p><h3 id="2-3-定期删除"><a href="#2-3-定期删除" class="headerlink" title="2.3 定期删除"></a>2.3 定期删除</h3><blockquote><p>两种方案都走极端，有没有折中方案？  </p></blockquote><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903111712055.png" alt="image-20220903111712055"></p><p>Redis启动服务器初始化时，读取配置server.hz的值，默认为10</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903111438004.png" alt="image-20220903111438004"></p><p>activeExpireCycle()对每个expires[*]逐一进行检测，每次执行250ms&#x2F;server.hz</p><p>对某个expires[*]检测时，随机挑选W个key检测</p><ul><li>如果key超时，删除key</li><li>如果一轮中删除的key的数量&gt;W*25%，循环该过程</li><li>如果一轮中删除的key的数量≤W*25%，检查下一个expires[*]， 0-15循环</li><li>W取值&#x3D;ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值</li></ul><p>参数current_db用于记录activeExpireCycle() 进入哪个expires[*] 执行</p><p>如果activeExpireCycle()执行时间到期，下次从current_db继续向下执行</p><p>周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度  </p><p>特点1： CPU性能占用设置有峰值，检测频度可自定义设置</p><p>特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理</p><p>总结：周期性抽查存储空间（随机抽查，重点抽查）</p><h3 id="2-4-删除策略对比"><a href="#2-4-删除策略对比" class="headerlink" title="2.4 删除策略对比"></a>2.4 删除策略对比</h3><ol><li>定时删除<ul><li>节约内存，无占用</li><li>不分时段占用CPU资源，频度高</li><li>拿时间换空间</li></ul></li><li>惰性删除<ul><li>内存占用严重</li><li>延时执行， CPU利用率高</li><li>拿空间换时间</li></ul></li><li>定期删除<ul><li>内存定期随机清理</li><li>每秒花费固定的CPU资源维护内存</li><li>随机抽查，重点抽查</li></ul></li></ol><h2 id="3-数据淘汰策略"><a href="#3-数据淘汰策略" class="headerlink" title="3. 数据淘汰策略"></a>3. 数据淘汰策略</h2><p>当新数据进入redis时，如果内存不足怎么办？</p><p>Redis使用内存存储数据，在执行每一个命令前，会调用<code>freeMemoryIfNeeded()</code>检测内存是否充足。如果内存不满足新加入数据的最低存储要求， redis要临时删除一些数据为当前指令清理存储空间。<strong>清理数据的策略称为逐出算法</strong>。  </p><p>注意：逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕后，如果不能达到内存清理的要求，将出现错误信息。  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(error) OOM <span class="built_in">command</span> not allowed when used memory &gt;<span class="string">&#x27;maxmemory&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="3-1-影响数据淘汰策略的相关配置"><a href="#3-1-影响数据淘汰策略的相关配置" class="headerlink" title="3.1 影响数据淘汰策略的相关配置"></a>3.1 影响数据淘汰策略的相关配置</h3><ol><li><p>最大可使用内存</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxmemory</span><br></pre></td></tr></table></figure><p>占用物理内存的比例，默认值为0，表示不限制。生产环境中根据需求设定，通常设置在50%以上。  </p></li><li><p>每次选取待删除数据的个数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxmemory-samples</span><br></pre></td></tr></table></figure><p>选取数据时并不会全库扫描，导致严重的性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据  </p></li><li><p>删除策略</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxmemory-policy</span><br></pre></td></tr></table></figure><p>达到最大内存后的，对被挑选出来的数据进行删除的策略</p></li></ol><h3 id="3-2-删除-淘汰-策略"><a href="#3-2-删除-淘汰-策略" class="headerlink" title="3.2 删除(淘汰)策略"></a>3.2 删除(淘汰)策略</h3><ul><li><p>检测易失数据（可能会过期的数据集server.db[i].expires ）</p><ol><li><code>volatile-lru</code>（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li><li><code>volatile-lfu</code>（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰</li><li><code>volatile-ttl</code>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li><li><code>volatile-random</code>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li></ol></li><li><p>检测全库数据（所有数据集server.db[i].dict ）</p><ol><li><code>allkeys-lru</code>（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）</li><li><code>allkeys-lfu</code>（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key</li><li><code>allkeys-random</code>：从数据集（server.db[i].dict）中任意选择数据淘汰</li></ol></li><li><p>放弃数据驱逐</p><ol><li><code>no-eviction</code>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</li></ol></li></ul><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220903120059567.png" alt="image-20220903120059567"></p><h3 id="3-3-数据逐出策略配置依据"><a href="#3-3-数据逐出策略配置依据" class="headerlink" title="3.3 数据逐出策略配置依据"></a>3.3 数据逐出策略配置依据</h3><p>使用INFO命令输出监控信息，查询缓存 hit 和 miss 的次数，根据业务需求调优Redis配置  </p>]]></content>
      
      
      <categories>
          
          <category> DataBase </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis的持久化</title>
      <link href="/posts/195f683a.html"/>
      <url>/posts/195f683a.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis的持久化"><a href="#Redis的持久化" class="headerlink" title="Redis的持久化"></a>Redis的持久化</h1><p>Redis是一个基于内存的数据库，所有的数据都存放在内存中，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。</p><p>Redis的持久化机制有两种，第一种是RDB快照，第二种是AOF日志。RDB快照是一次全量备份，AOF是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本</p><h2 id="1-RDB持久化"><a href="#1-RDB持久化" class="headerlink" title="1. RDB持久化"></a>1. RDB持久化</h2><p>RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。</p><h3 id="1-1-执行时机"><a href="#1-1-执行时机" class="headerlink" title="1.1 执行时机"></a>1.1 执行时机</h3><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1、执行save命令</strong></p><p>执行下面的命令，可以立即执行一次RDB：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902151306413.png" alt="image-20220902151306413"></p><p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。如果数据量大的话会造成长时间的阻塞，所以线上环境一般禁止使用,一般只有在数据迁移时可能用到。</p><p><strong>2、执行bgsave命令</strong></p><p>下面的命令可以异步执行RDB：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902151631568.png" alt="image-20220902151631568"></p><p>这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。</p><p><strong>3、Redis停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4、触发RDB条件时</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save &quot;&quot; 则表示禁用RDB</span></span><br><span class="line"><span class="attr">save</span> <span class="string">900 1  </span></span><br><span class="line"><span class="attr">save</span> <span class="string">300 10  </span></span><br><span class="line"><span class="attr">save</span> <span class="string">60 10000 </span></span><br></pre></td></tr></table></figure><p>RDB的其它配置也可以在redis.conf文件中设置：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱</span></span><br><span class="line"><span class="attr">rdbcompression</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># RDB文件名称</span></span><br><span class="line"><span class="attr">dbfilename</span> <span class="string">dump.rdb  </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 文件保存的路径目录</span></span><br><span class="line"><span class="attr">dir</span> <span class="string">./ </span></span><br></pre></td></tr></table></figure><h3 id="1-2-RDB原理"><a href="#1-2-RDB原理" class="headerlink" title="1.2 RDB原理"></a>1.2 RDB原理</h3><p>执行bgsave命令时，Redis主进程会fork一个子进程来完成RDB的过程，会先将数据写入到一个临时二进制文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件（可以理解为Copy On Write机制）。Redis主进程阻塞时间只有fork阶段的那一下。相对于save，阻塞时间很短。基本上 Redis 内部所有的RDB操作都是采用 bgsave 命令。</p><p>fork采用的是copy-on-write技术：</p><ul><li>当主进程执行读操作时，访问共享内存；</li><li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li></ul><blockquote><p>fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。</p></blockquote><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902152351517.png" alt="image-20220902152351517"></p><h3 id="1-3-小结"><a href="#1-3-小结" class="headerlink" title="1.3 小结"></a>1.3 小结</h3><p><strong>RDB执行流程：</strong></p><ol><li>执行bgsave命令的时候，Redis主进程会检查是否有子进程在执行RDB&#x2F;AOF持久化任务，如果有的话，直接返回，主要是为了性能的考虑，防止两个进程同时对磁盘进行写入操作</li><li>Redis主进程fork一个子进程来执行执行RDB操作，fork操作会对主进程造成阻塞（影响Redis的读写），fork操作完成后会发消息给主进程，从而不再阻塞主进程（阻塞仅指主进程fork子进程的过程，后续子进程执行操作时不会阻塞）</li><li>RDB子进程把Redis主进程的内存数据，写入到一个临时的快照文件，持久化完成后，再使用临时快照文件替换掉原来的RDB文件。（该过程中主进程的读写不受影响，但Redis的写操作不会同步到主进程的主内存中，而是会写到一个临时的内存区域作为一个副本）</li><li>子进程完成RDB持久化后会发消息给主进程，通知RDB持久化完成，并将步骤（3）中的内存副本中的增量写数据同步到主内存</li></ol><p><strong>优势：</strong></p><ol><li>RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。</li><li>对于大规模数据的恢复，且对于数据恢复的完整性不是非常敏感的场景，RDB的恢复速度要比AOF方式更加的高效。</li><li>生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</li></ol><p><strong>劣势：</strong></p><ol><li>fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。</li><li>当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。</li><li>在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改。</li></ol><hr><h2 id="2-AOF持久化"><a href="#2-AOF持久化" class="headerlink" title="2. AOF持久化"></a>2. AOF持久化</h2><p>每次都使用RDB机制全量备份的方式是非常耗时间的，因此Redis还提供了另一种持久化机制AOF（append only file）。AOF日志是持续增量的备份，将Redis执行过的每个写操作以日志的形式记录下来(读操作不记录)，只许追加文件但不可以改写文件(appendonly.aof文件)。redis启动的时候会读取该文件进行数据恢复，根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。</p><h3 id="2-1-AOF原理"><a href="#2-1-AOF原理" class="headerlink" title="2.1 AOF原理"></a>2.1 AOF原理</h3><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902153733141.png" alt="image-20220902153733141"></p><h3 id="2-2-AOF配置"><a href="#2-2-AOF配置" class="headerlink" title="2.2 AOF配置"></a>2.2 AOF配置</h3><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 是否开启AOF功能，默认是no</span></span><br><span class="line"><span class="attr">appendonly</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"># AOF文件的名称</span></span><br><span class="line"><span class="attr">appendfilename</span> <span class="string">&quot;appendonly.aof&quot;</span></span><br></pre></td></tr></table></figure><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表示每执行一次写命令，立即记录到AOF文件</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">always </span></span><br><span class="line"><span class="comment"># 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">everysec </span></span><br><span class="line"><span class="comment"># 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">no</span></span><br></pre></td></tr></table></figure><p>三种策略对比：</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902153828843.png" alt="image-20220902153828843"></p><h3 id="2-3-AOF文件重写"><a href="#2-3-AOF文件重写" class="headerlink" title="2.3 AOF文件重写"></a>2.3 AOF文件重写</h3><p>因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行<code>bgrewriteaof</code>命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902153939385.png" alt="image-20220902153939385"></p><p>如图，AOF原本有三个命令，但是<code>set num 123 和 set num 666</code>都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。</p><p>所以重写命令后，AOF文件内容就是：<code>mset name jack num 666</code></p><p><strong>重写原理</strong>：AOF文件持续增长而过大时，会fork出一条新进程来重写aof文件，将内存中的整个数据库内容用命令的方式重写了一个新的aof文件（注意：在重写时并不是读取旧的aof文件），在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。</p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AOF文件比上次文件 增长超过多少百分比则触发重写</span></span><br><span class="line"><span class="attr">auto-aof-rewrite-percentage</span> <span class="string">100</span></span><br><span class="line"><span class="comment"># AOF文件体积最小多大以上才触发重写 </span></span><br><span class="line"><span class="attr">auto-aof-rewrite-min-size</span> <span class="string">64mb </span></span><br></pre></td></tr></table></figure><h3 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4 小结"></a>2.4 小结</h3><p><strong>优点：</strong></p><ol><li>AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。</li><li>AOF只是追加写日志文件，对服务器性能影响较小，速度比RDB要快，消耗的内存较少</li><li>AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</li><li>AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。</li></ol><p><strong>劣势：</strong></p><ol><li>对于相同数据集的数据而言，aof文件要远大于rdb文件，恢复速度慢于rdb。</li><li>对于每秒一次同步的情况，aof运行效率要慢于rdb，不同步效率和rdb相同。</li></ol><p><strong>RDB和AOF的对比</strong></p><p>RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用</p><p><img src="https://blog-1309755336.cos.ap-guangzhou.myqcloud.com/images/image-20220902154439792.png" alt="image-20220902154439792"></p><blockquote><p>注：如果同时开启两种持久化方式，在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</p></blockquote><h2 id="3-Redis4-0的混合持久化"><a href="#3-Redis4-0的混合持久化" class="headerlink" title="3. Redis4.0的混合持久化"></a>3. Redis4.0的混合持久化</h2><ul><li>仅使用RDB快照方式恢复数据，由于快照时间粒度较大时，会丢失大量数据。</li><li>仅使用AOF重放方式恢复数据，日志性能相对 rdb 来说要慢。在 Redis 实例很大的情况下，启动需要花费很长的时间。</li></ul><p>为了解决这个问题，Redis4.0开始支持RDB和AOF的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。RDB 文件的内容和增量的 AOF 日志文件存在一起，这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。</p><ul><li>大量数据使用粗粒度（时间上）的rdb快照方式，性能高，恢复时间快。</li><li>增量数据使用细粒度（时间上）的AOF日志方式，尽量保证数据的不丢失。</li></ul><p>在Redis重启时，进行AOF重写的时候就直接把RDB的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB和 AOF 的优点，快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是AOF 格式，可读性较差。</p><p>另外，可以使用下面这种方式：Master使用AOF，Slave使用RDB快照，master需要首先确保数据完整性，它作为数据备份的第一选择；slave提供只读服务或仅作为备机，它的主要目的就是快速响应客户端read请求或灾切换。</p>]]></content>
      
      
      <categories>
          
          <category> DataBase </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/4a17b156.html"/>
      <url>/posts/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>category</title>
      <link href="/category/index.html"/>
      <url>/category/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>link</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* @font-face {  font-family: Candyhome;  src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/Candyhome.ttf);  font-display: swap;  font-weight: lighter;} */@font-face {    font-family: ZhuZiAYuanJWD;    src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2);    font-display: swap;    font-weight: lighter;}div#menus {    font-family: 'ZhuZiAYuanJWD';}h1#site-title {    font-family: ZhuZiAYuanJWD;    font-size: 3em !important;}a.article-title,a.blog-slider__title,a.categoryBar-list-link,h1.post-title {    font-family: ZhuZiAYuanJWD;}.iconfont {    font-family: 'iconfont' !important;    font-size: 3em;    /* 可以定义图标大小 */    font-style: normal;    -webkit-font-smoothing: antialiased;    -moz-osx-font-smoothing: grayscale;}/* 时间轴生肖icon */svg.icon {    /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */    width: 1em;    height: 1em;    /* width和height定义图标的默认宽度和高度*/    vertical-align: -0.15em;    fill: currentColor;    overflow: hidden;}.icon-zhongbiao::before {    color: #f7c768;}/* bilibli番剧插件 *//* .bangumi-active {    background: #dbecfe !important;    border-radius: 10px !important;} */a.bangumi-tab:hover {    text-decoration: none !important;}.bangumi-button:hover {    background: #dbecfe !important;    border-radius: 10px !important;}a.bangumi-button.bangumi-nextpage:hover {    text-decoration: none !important;}.bangumi-button {    padding: 5px 10px !important;}a.bangumi-tab {    padding: 5px 10px !important;}svg.icon.faa-tada {    font-size: 1.1em;}/* 解决artitalk的图标问题 */#uploadSource>svg {    width: 1.19em;    height: 1.5em;}/*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */#page-header:not(.not-top-img):before {    background-color: transparent !important;}/* 首页文章卡片 */#recent-posts>.recent-post-item {    background: rgba(255, 255, 255, 0.9);}/* 首页侧栏卡片 */#aside-content .card-widget {    background: rgba(255, 255, 255, 0.9);}/* 文章页面正文背景 */div#post {    background: rgba(255, 255, 255, 0.9);}/* 分页页面 */div#page {    background: rgba(255, 255, 255, 0.9);}/* 归档页面 */div#archive {    background: rgba(255, 255, 255, 0.9);}/* 标签页面 */div#tag {    background: rgba(255, 255, 255, 0.9);}/* 分类页面 */div#category {    background: rgba(255, 255, 255, 0.9);}/*夜间模式伪类遮罩层透明*/[data-theme='dark'] #recent-posts>.recent-post-item {    background: #121212;}[data-theme='dark'] .card-widget {    background: #121212 !important;}[data-theme='dark'] div#post {    background: #121212 !important;}[data-theme='dark'] div#tag {    background: #121212 !important;}[data-theme='dark'] div#archive {    background: #121212 !important;}[data-theme='dark'] div#page {    background: #121212 !important;}[data-theme='dark'] div#category {    background: #121212 !important;}[data-theme='dark'] div#category {    background: transparent !important;}/* 页脚透明 */#footer {    background: transparent !important;}/* 头图透明 */#page-header {    background: transparent !important;}#rightside>div>button {    border-radius: 5px;}/* 滚动条 */::-webkit-scrollbar {    width: 10px;    height: 10px;}::-webkit-scrollbar-thumb {    background-color: #49b1f5;    border-radius: 2em;}::-webkit-scrollbar-corner {    background-color: transparent;}::-moz-selection {    color: #fff;    background-color: #49b1f5;}/* 音乐播放器 *//* .aplayer .aplayer-lrc {  display: none !important;} */.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {    left: -66px !important;    transition: all 0.3s;    /* 默认情况下缩进左侧66px，只留一点箭头部分 */}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {    left: 0 !important;    transition: all 0.3s;    /* 鼠标悬停是左侧缩进归零，完全显示按钮 */}.aplayer.aplayer-fixed {    z-index: 999999 !important;}/* 评论框  */.vwrap {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 30px 0px;}/* 设置评论框 */.vcard {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 0px 0px;}/* 鼠标图标 *//* body {    cursor: url('/img/x1.cur'), auto;} */a,[type='button']:not(:disabled),[type='reset']:not(:disabled),[type='submit']:not(:disabled),button:not(:disabled) {    cursor: url('/img/x2.cur'), auto !important;}/* md网站下划线 */#article-container a:hover {    text-decoration: none !important;}#article-container #hpp_talk p img {    display: inline;}/* 404页面 */#error-wrap {    position: absolute;    top: 40%;    right: 0;    left: 0;    margin: 0 auto;    padding: 0 1rem;    max-width: 1000px;    transform: translate(0, -50%);}#error-wrap .error-content {    display: flex;    flex-direction: row;    justify-content: center;    align-items: center;    margin: 0 1rem;    height: 18rem;    border-radius: 8px;    background: var(--card-bg);    box-shadow: var(--card-box-shadow);    transition: all 0.3s;}#error-wrap .error-content .error-img {    box-flex: 1;    flex: 1;    height: 100%;    border-top-left-radius: 8px;    border-bottom-left-radius: 8px;    background-color: #49b1f5;    background-position: center;    background-size: cover;}#error-wrap .error-content .error-info {    box-flex: 1;    flex: 1;    padding: 0.5rem;    text-align: center;    font-size: 14px;    font-family: Titillium Web, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft JhengHei', 'Microsoft YaHei', sans-serif;}#error-wrap .error-content .error-info .error_title {    margin-top: -4rem;    font-size: 9em;}#error-wrap .error-content .error-info .error_subtitle {    margin-top: -3.5rem;    word-break: break-word;    font-size: 1.6em;}#error-wrap .error-content .error-info a {    display: inline-block;    margin-top: 0.5rem;    padding: 0.3rem 1.5rem;    background: var(--btn-bg);    color: var(--btn-color);}#body-wrap.error .aside-list {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    bottom: 0px;    position: absolute;    padding: 1rem;    width: 100%;    overflow: scroll;}#body-wrap.error .aside-list .aside-list-group {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    max-width: 1200px;    margin: 0 auto;}#body-wrap.error .aside-list .aside-list-item {    padding: 0.5rem;}#body-wrap.error .aside-list .aside-list-item img {    width: 100%;    object-fit: cover;    border-radius: 12px;}#body-wrap.error .aside-list .aside-list-item .thumbnail {    overflow: hidden;    width: 230px;    height: 143px;    background: var(--heo-card-bg);    display: flex;}#body-wrap.error .aside-list .aside-list-item .content .title {    -webkit-line-clamp: 2;    overflow: hidden;    display: -webkit-box;    -webkit-box-orient: vertical;    line-height: 1.5;    justify-content: center;    align-items: flex-end;    align-content: center;    padding-top: 0.5rem;    color: white;}#body-wrap.error .aside-list .aside-list-item .content time {    display: none;}/* 代码框主题 */#article-container figure.highlight {    border-radius: 10px;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
